{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.10 (tensorflow)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Download MTCNN"
   ],
   "metadata": {
    "id": "AZX7pXxRhOyp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install mtcnn\n",
    "from mtcnn import MTCNN\n",
    "import cv2"
   ],
   "metadata": {
    "id": "3RflIu7g4ahG",
    "outputId": "11f76e06-db52-40f2-b89e-fd530922763e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m18.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from mtcnn) (2.12.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from mtcnn) (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.22.4)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Packages"
   ],
   "metadata": {
    "id": "8c3hdFrKg_hj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR100, CIFAR10\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUMPeKqVg-Wh",
    "outputId": "0e33dda4-610e-412d-978b-f08f36622ba1"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build The CNN"
   ],
   "metadata": {
    "id": "mjHBUBtmhUcA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, numChannels, numClasses):\n",
    "        super(CNN, self).__init__()\n",
    "        self.classes = numClasses\n",
    "\n",
    "        #######################################################\n",
    "        # *** TASK 1 *** \n",
    "        # Define your \"Lego bricks\": all the layers of your CNN \n",
    "        # you will be using later in the \"forward\" function\n",
    "        # pytorch implementation: nn.Conv2d\n",
    "        # you can check https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "        # If you haven't done so before, consider playing with this demo of CNNs:\n",
    "        # https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "        #######################################################\n",
    "        # *** THINK *** What is the relationship between output feature channel and number of kernels?\n",
    "        # *** THINK *** Can you draw a picture to describe the relationship among input size, \n",
    "        #               kernel size and output size in a convolution layer?\n",
    "        #######################################################\n",
    "\n",
    "        # Convolutional layers:\n",
    "        self.conv1 = nn.Conv2d(numChannels, 96, 11, stride=4)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, stride=1)\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, stride=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, stride=1)\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, stride=1)\n",
    "\n",
    "        # Activation function:\n",
    "        # check https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Pooling layer:\n",
    "        # check https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # Batch normalization layers:\n",
    "        self.batchnorm1 = nn.BatchNorm2d(96)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Fully-connected layers:\n",
    "        self.fc1 = nn.Linear(2304, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "\n",
    "        #######################################################\n",
    "        # *** THINK *** We have very specific numbers of neurons (2304 and 1024) \n",
    "        #               in fully-connected layers (fc1 and fc2). Make sure you understand \n",
    "        #               where these numbers are comming from (and when they can be different).\n",
    "        #######################################################\n",
    "        \n",
    "        #######################################################\n",
    "        # *** THINK *** As we are using CrossEntropy loss during training, so a softmax activation\n",
    "        #               function (= implemented as a softmax layer to apply it to the whole layer)\n",
    "        #               is not needed here since it's already included in Pytorch's implementation \n",
    "        #               of cross-entropy loss. See this for details: \n",
    "        #               https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "        #######################################################\n",
    "\n",
    "    # Evaluation function\n",
    "    def evaluate(self, model, dataloader, classes, device):\n",
    "\n",
    "        # We need to switch the model into the evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Prepare to count predictions for each class\n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "        # For all test data samples:\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            images = images.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "            # Count the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                \n",
    "                # If you want to see real and predicted labels for all samples:\n",
    "                # print(\"Real class: \" + classes[label] + \", predicted = \" + classes[prediction])\n",
    "                \n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "            \n",
    "            print(\"------\")\n",
    "            for i in range(10):\n",
    "              print(classes[i], \":\", correct_pred[classes[i]] / total_pred [classes[i]])\n",
    "            # print(\"correct\", correct_pred)\n",
    "            # print(\"total\", total_pred)\n",
    "        # Calculate the overall accuracy on the test set\n",
    "        acc = sum(correct_pred.values()) / sum(total_pred.values())\n",
    "\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = resize(x, size=[256])\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "        # *** TASK 1 *** Now Use your \"Lego bricks\" to build the CNN network \n",
    "        #                by defining all operations in a correct order:\n",
    "\n",
    "        # Convolutional, ReLU, MacPooling and Batchnorm layers go first\n",
    "        # (see the slides with instructions for the network architecture)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.batchnorm1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    " \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "\n",
    "        # x = self. ...\n",
    "        # ...\n",
    "\n",
    "\n",
    "\n",
    "        # *** THINK *** What if we remove one of the layers? Will the network still work?\n",
    "\n",
    "        # After the last pooling operation, and before the first \n",
    "        # fully-connected layer, we need to \"flatten\" our tensors\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # *** THINK *** Can fully-connected layers accept data if they are not flattened?\n",
    "\n",
    "        # Finally, we need our two-layer perceptron (two fully-connected layers) at the end of the network:\n",
    "        # x = self. ...\n",
    "        # ...\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "id": "27aB-17IhZ5A"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Custom Dataset\n"
   ],
   "metadata": {
    "id": "qooKJ7_gg8fG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform):\n",
    "        self.img_labels = pd.read_csv(label_dir, header=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        image = image.to(torch.float) / 256.\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, label)\n",
    "\n",
    "# Transform images:\n",
    "# a) to tensor: convert the PIL image or numpy.ndarray to tensor\n",
    "# b) Z-normalize a tensor image (using its mean and standard deviation)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ],
   "metadata": {
    "id": "G6TrE9mog8P0"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Our Data"
   ],
   "metadata": {
    "id": "R8pMk7JfhkcS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#######################################################\n",
    "# *** TASK 1 ***\n",
    "# Define number of epochs and batch size:\n",
    "\n",
    "# Path to the sampled CIFAR-100 dataset:\n",
    "image_dir = 'image-source/test-all-source/' ### change this\n",
    "\n",
    "# Path to the labels of the sampled CIFAR-100 subset\n",
    "label_dir = 'cse40868-final-project-labels.csv'### change this\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "\n",
    "# *** THINK *** Should we set the # of epochs as large as possible? Why?\n",
    "# *** THINK *** If we find that the evaluation accuracy is low, should we increase or decrease the # of epochs?\n",
    "\n",
    "#\n",
    "#######################################################\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "# train_data = CIFAR10(\"./data\", train=True, download=True, transform=ToTensor())\n",
    "# test_data = CIFAR10(\"./data\", train=False, download=True, transform=ToTensor())\n",
    "data = FaceDataset(img_dir=image_dir, label_dir=label_dir, transform=transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
    "\n",
    "train_len = int(len(data) * 0.8)\n",
    "val_len = int(len(data) * 0.1)\n",
    "test_len = int(len(data) - train_len - val_len)\n",
    "train_data, val_data, test_data = random_split(data, [train_len, val_len, test_len])\n",
    "classes = [\"me-source\", \"everyone-source\"] ##### change this\n",
    "\n",
    "# Prepare data loaders for train, validation and test data splits \n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)"
   ],
   "metadata": {
    "id": "Yh36z9oEhoo2"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Evaluation"
   ],
   "metadata": {
    "id": "HkR0RIQJhoBs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # *** TASK 1 ***\n",
    "\n",
    "    # Specify the operation mode:\n",
    "    # 'train' = training with your train and validation data splits\n",
    "    # 'eval'  = evaluation of the trained model with your test data split \n",
    "    mode = 'train'\n",
    "\n",
    "    # Path where you plan to save the best model during training\n",
    "    my_best_model = \"/CSE40868_final_project_best_model.pth\"\n",
    "\n",
    "\n",
    "    # Set the device (GPU or CPU, depending on availability)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Currently using device: \", device)\n",
    "\n",
    "    # Initialize the model and print out its configuration\n",
    "    model = CNN(numChannels = 3, numClasses = 10)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"\\n\\nModel summary:\\n\\n\")\n",
    "    summary(model, input_size=(3, 32, 32))\n",
    "\n",
    "    if mode == \"train\":\n",
    "\n",
    "        print(\"\\n\\nTraining starts!\\n\\n\")\n",
    "        \n",
    "        model.train()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    #######################################################\n",
    "    # *** TASK 1 *** Try different optimizers (can be Adam or SGD). \n",
    "    #                Try different parameters (learning rate, momentum). \n",
    "    #                Can you notice any difference among these configurations?\n",
    "    #                Try to explain what you observed in a few sentences \n",
    "    #                (there's a space at the end of this notebook for answers).\n",
    "    #######################################################\n",
    "        \n",
    "        running_loss = .0\n",
    "        best_acc = .0\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Starting epoch {epoch + 1}\")\n",
    "            for idx, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "                # Get the inputs (data is a list of [inputs, labels])\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss = loss.detach().cpu().numpy()\n",
    "                inputs = inputs.detach().cpu().numpy()\n",
    "                labels = labels.detach().cpu().numpy()\n",
    "                running_loss += loss\n",
    "\n",
    "            # Evaluate the accuracy after each epoch\n",
    "            acc = model.evaluate(model, val_loader, classes, device)\n",
    "            if acc > best_acc:\n",
    "                print(f\"Better validation accuracy achieved: {acc * 100:.2f}%\")\n",
    "                best_acc = acc\n",
    "                print(f\"Saving this model as: {my_best_model}\")\n",
    "                torch.save(model.state_dict(), my_best_model)\n",
    "\n",
    "    # And here we evaluate the trained model with the test data\n",
    "    elif mode == \"eval\":\n",
    "\n",
    "        print(\"\\n\\nValidating the trained model:\")\n",
    "        print(f\"Loading checkpoint from {my_best_model}\")\n",
    "        model.load_state_dict(torch.load(my_best_model))\n",
    "        acc = model.evaluate(model, test_loader, classes, device)\n",
    "        print(f\"Accuracy on the test (unknown) data: {acc * 100:.2f}%\")\n",
    "\n",
    "    else:\n",
    "        print(\"'mode' argument should either be 'train' or 'eval'\")"
   ],
   "metadata": {
    "id": "4zhZdWeyh24w",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "f56bbaba-1ada-47fc-bd5e-cda3a400f5cf"
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using device:  cpu\n",
      "\n",
      "\n",
      "Model summary:\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 62, 62]          34,944\n",
      "              ReLU-2           [-1, 96, 62, 62]               0\n",
      "         MaxPool2d-3           [-1, 96, 31, 31]               0\n",
      "       BatchNorm2d-4           [-1, 96, 31, 31]             192\n",
      "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-6          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-7          [-1, 256, 13, 13]               0\n",
      "       BatchNorm2d-8          [-1, 256, 13, 13]             512\n",
      "            Conv2d-9          [-1, 384, 11, 11]         885,120\n",
      "             ReLU-10          [-1, 384, 11, 11]               0\n",
      "           Conv2d-11            [-1, 384, 9, 9]       1,327,488\n",
      "             ReLU-12            [-1, 384, 9, 9]               0\n",
      "           Conv2d-13            [-1, 256, 7, 7]         884,992\n",
      "             ReLU-14            [-1, 256, 7, 7]               0\n",
      "        MaxPool2d-15            [-1, 256, 3, 3]               0\n",
      "           Linear-16                 [-1, 1024]       2,360,320\n",
      "             ReLU-17                 [-1, 1024]               0\n",
      "           Linear-18                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 6,110,274\n",
      "Trainable params: 6,110,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.95\n",
      "Params size (MB): 23.31\n",
      "Estimated Total Size (MB): 35.28\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training starts!\n",
      "\n",
      "\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1572 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/colinlo/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "  File \"/Users/colinlo/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/colinlo/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/colinlo/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'FaceDataset' on <module '__main__' (built-in)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'FaceDataset' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/1572 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 65881) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1120\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    112\u001B[0m timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 65881) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 47\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, data \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(train_loader), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader)):\n\u001B[1;32m     48\u001B[0m \n\u001B[1;32m     49\u001B[0m         \u001B[38;5;66;03m# Get the inputs (data is a list of [inputs, labels])\u001B[39;00m\n\u001B[1;32m     50\u001B[0m         inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m     51\u001B[0m         inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/tqdm/std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1315\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1316\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1279\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1282\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1283\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1284\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1132\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1133\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(pids_str)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 65881) exited unexpectedly"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
